# Problem Definition: Phase 0 Assessment Inconsistency

**Date**: 2026-01-19
**Status**: ✅ RESOLVED - Quick Start Architecture
**Resolution Date**: 2026-01-19
**Cost Incurred**: ~$17+ in failed testing attempts (before resolution)

---

## Resolution Summary

> **RESOLVED by [ADR-006: Quick Start Architecture](../../../startupai-crew/docs/adr/006-quick-start-architecture.md)**
>
> The 7-stage AI conversation was replaced with **Quick Start** - a single form input that takes 30 seconds, costs $0 in AI, and is 100% deterministic. The assessment inconsistency problem no longer exists because there is no AI in Phase 0.
>
> **Key changes:**
> - Phase 0 is now a simple form: business idea + optional context
> - The Founder's Brief is generated by Phase 1 AI research, not collected during onboarding
> - All code related to 7-stage progression, quality assessment, and topic coverage will be deleted
> - E2E tests are now deterministic and cost $0

---

## Historical Context (Archived)

The information below documents the original problem for historical reference.

### Original Executive Summary

The founder onboarding system (Phase 0) produced inconsistent progress calculations. The same 7-stage conversation sometimes completed with 85%+ progress, sometimes stalled at 57-76%. This inconsistency made the system unreliable and blocked all downstream phases.

---

## System Architecture

### Two-Pass Architecture

```
User Message → /api/chat/stream (Pass 1) → AI Response (streaming)
                                              ↓
                        /api/chat/save (Pass 2) → Assessment → Progress Update
```

**Pass 1** (`/api/chat/stream`): Stateless streaming endpoint that returns AI conversational responses. No persistence.

**Pass 2** (`/api/chat/save`): After stream completes, client calls this endpoint with both messages. This triggers:
1. Quality assessment via `assessFounderConversation()`
2. Stage advancement check via `shouldFounderAdvanceStage()`
3. Atomic database update via `apply_onboarding_turn` RPC

### Key Files

| File | Purpose |
|------|---------|
| `src/app/api/chat/stream/route.ts` | Pass 1: AI streaming |
| `src/app/api/chat/save/route.ts` | Pass 2: Assessment + persistence |
| `src/lib/onboarding/founder-quality-assessment.ts` | Assessment logic |
| `src/lib/onboarding/founder-stages-config.ts` | Stage configuration |

---

## The Problem

### Observed Behavior

Running the same E2E test multiple times produces different results:

| Run | Stage 1 | Stage 2 | Stage 3 | Stage 4 | Stage 5 | Stage 6 | Stage 7 | Final |
|-----|---------|---------|---------|---------|---------|---------|---------|-------|
| 1   | 0%      | 14%     | 28%     | 42%     | 71%     | 71%     | 85%     | **PASS** |
| 2   | 0%      | 14%     | 42%     | 64%     | 71%     | 76%     | 76%     | **FAIL** |
| 3   | 0%      | 7%      | 7%      | 28%     | 42%     | 57%     | 57%     | **FAIL** |
| 4   | 85%     | 85%     | ...timeout...     |         |         |         |         | **FAIL** |

### Expected Behavior

The same conversation should produce consistent progress:
- Each stage should advance when 75% of topics are covered
- Final progress should consistently reach 85%+
- Tests should be deterministic

---

## Root Cause Analysis

### Hypothesis 1: LLM Assessment Variability

The `assessFounderConversation()` function uses an LLM to determine which topics were "covered" in the conversation. Different LLM responses produce different `topicsCovered` arrays.

**Evidence:**
- Using `xiaomi/mimo-v2-flash:free` sometimes identifies 3/4 topics, sometimes 2/4
- The same user response ("I want to build a meal planning app...") gets assessed differently

**Code Location** (`founder-quality-assessment.ts:155-245`):
```typescript
export function buildAssessmentPrompt(
  stage: number,
  history: ConversationMessage[],
  existingBrief: Record<string, unknown>
): string {
  // The prompt asks the LLM to identify which topics were discussed
  // This is inherently non-deterministic
}
```

### Hypothesis 2: Topic Coverage Threshold Logic

The stage advancement logic in `shouldFounderAdvanceStage()` uses topic-based advancement:

```typescript
// founder-quality-assessment.ts:391-399
const requiredTopics = config.dataToCollect;
const topicsCovered = assessment.topicsCovered || [];
const topicCoverageRatio = topicsCovered.length / requiredTopics.length;

const topicThreshold = Math.min(config.progressThreshold, 0.75);
const topicBasedAdvance = topicCoverageRatio >= topicThreshold;
```

**Problem**: If the LLM returns `topicsCovered: ["business_concept", "inspiration"]` (2 topics) vs `topicsCovered: ["business_concept", "inspiration", "current_stage"]` (3 topics), the ratio changes from 0.5 to 0.75, which determines if we advance.

### Hypothesis 3: Stage-Specific Thresholds Are Inconsistent

Each stage has different `progressThreshold` values:

| Stage | Threshold | Topics Required | Minimum to Advance |
|-------|-----------|-----------------|-------------------|
| 1     | 0.70      | 4               | 3 topics (0.75)   |
| 2     | 0.75      | 4               | 3 topics (0.75)   |
| 3     | 0.80      | 4               | 3 topics (0.75)   |
| 4     | 0.75      | 4               | 3 topics (0.75)   |
| 5     | 0.70      | 4               | 3 topics (0.75)   |
| 6     | 0.75      | 5               | 4 topics (0.80)   |
| 7     | 0.85      | 4               | 3 topics (0.75)   |

**Note**: The code uses `Math.min(config.progressThreshold, 0.75)` which caps the threshold at 75%, making some config values irrelevant.

### Hypothesis 4: Message Filtering Issues

The assessment only looks at messages tagged with the current stage:

```typescript
// founder-quality-assessment.ts:163-170
const stageMessages = history.filter(m => m.stage === stage);

// FALLBACK: If no stage-tagged messages, include all non-system messages
const messagesForAssessment =
  stageMessages.length > 0
    ? stageMessages
    : history.filter(m => m.role !== 'system');
```

If messages aren't properly tagged with stages, the assessment might evaluate the wrong conversation subset.

---

## Data Flow Trace

### Step-by-Step Flow

1. **User sends message** → Frontend calls `/api/chat/stream`

2. **Stream completes** → Frontend collects AI response

3. **Save triggered** → Frontend calls `/api/chat/save` with:
   ```json
   {
     "sessionId": "...",
     "messageId": "unique-id",
     "userMessage": { "role": "user", "content": "...", "timestamp": "..." },
     "assistantMessage": { "role": "assistant", "content": "...", "timestamp": "..." }
   }
   ```

4. **Assessment runs** → `assessFounderConversation()` is called:
   - Builds prompt with stage config and conversation history
   - Calls LLM via `generateObject()` to get structured assessment
   - Returns `QualityAssessment` with `topicsCovered`, `coverage`, etc.

5. **Advancement check** → `shouldFounderAdvanceStage()`:
   ```typescript
   topicCoverageRatio >= 0.75  // Primary check
   // OR
   (stageMessageCount >= 6 && coverage >= 0.6)  // Fallback
   ```

6. **Database update** → `apply_onboarding_turn` RPC atomically updates:
   - `conversation_history`
   - `current_stage` (if advancing)
   - `overall_progress`
   - `stage_data.brief` (extracted data)

---

## Specific Questions for Investigation

### Q1: Why does `topicsCovered` vary?

The assessment prompt (`buildAssessmentPrompt`) asks the LLM:
> "List which of the required data fields have been DISCUSSED in this stage"

Different LLMs (or the same LLM with different temperatures) interpret "discussed" differently.

**To investigate:**
- Log the exact `topicsCovered` array returned by each assessment
- Compare against the actual conversation content
- Determine if the prompt is ambiguous

### Q2: Is the fallback advancement working?

The fallback should trigger after 6+ messages:
```typescript
const messageBasedAdvance =
  stageMessageCount !== undefined &&
  stageMessageCount >= 6 &&
  assessment.coverage >= 0.6;
```

**To investigate:**
- What is `stageMessageCount` at each stage?
- Is `assessment.coverage` reaching 0.6?

### Q3: Are messages being properly tagged with stages?

If messages aren't tagged with `stage: N`, the assessment might evaluate wrong messages.

**To investigate:**
- Dump `conversation_history` from database after test
- Verify each message has correct `stage` field

### Q4: Is progress calculation correct?

`calculateOverallProgress()` uses:
```typescript
const baseProgress = Math.floor(((newStage - 1) / 7) * 100);
const stageWeight = Math.floor(100 / 7);  // ~14%
const qualityBasedProgress = baseProgress + Math.floor(coverage * stageWeight);
```

**To investigate:**
- Trace progress calculation for each assessment
- Verify the math produces expected values

---

## Files to Examine

### Primary Source Files

1. **`src/lib/onboarding/founder-quality-assessment.ts`**
   - `buildAssessmentPrompt()` - Line 155
   - `assessWithRetry()` - Line 270
   - `shouldFounderAdvanceStage()` - Line 379
   - `calculateOverallProgress()` - Line 535

2. **`src/lib/onboarding/founder-stages-config.ts`**
   - Stage definitions with `dataToCollect` and `progressThreshold`

3. **`src/app/api/chat/save/route.ts`**
   - Where assessment is triggered and results processed

### Database

- Table: `onboarding_sessions`
- RPC: `apply_onboarding_turn` (in Supabase)

### Test File

- `tests/e2e/16-phase0-founder-complete.spec.ts`

---

## Proposed Solutions

### Option A: Deterministic Topic Matching (No LLM)

Replace LLM-based topic detection with keyword/regex matching:
```typescript
function detectTopicsCovered(messages: ConversationMessage[], requiredTopics: string[]): string[] {
  const conversationText = messages.map(m => m.content).join(' ').toLowerCase();
  return requiredTopics.filter(topic => {
    const keywords = TOPIC_KEYWORDS[topic]; // Define keywords per topic
    return keywords.some(kw => conversationText.includes(kw));
  });
}
```

**Pros**: Deterministic, no LLM cost, fast
**Cons**: Less nuanced, may miss valid coverage

### Option B: Lower Thresholds + Message-Based Override

Make advancement easier:
```typescript
const topicThreshold = 0.5;  // 50% instead of 75%
const messageBasedAdvance = stageMessageCount >= 4 && coverage >= 0.4;
```

**Pros**: Simple change, more forgiving
**Cons**: Doesn't fix root cause, may advance too easily

### Option C: Use Cheaper Deterministic LLM

Use a model with lower temperature (0.0) and better JSON compliance:
```typescript
const { object } = await generateObject({
  model,
  schema: qualityAssessmentSchema,
  prompt,
  temperature: 0.0,  // Maximum determinism
});
```

**Pros**: Still uses LLM intelligence
**Cons**: Still fundamentally non-deterministic

### Option D: Hybrid Approach

1. Use keyword matching as primary topic detection
2. Use LLM only for data extraction (not gating)
3. Advance based on message count + keyword coverage

---

## Acceptance Criteria

The fix is successful when:

1. **Deterministic**: Same conversation produces same progress every time
2. **Completes**: 7-stage conversation reliably reaches 85%+ progress
3. **Zero Cost**: E2E tests cost $0 (uses deterministic logic or free tier)
4. **Testable**: Unit tests can verify topic detection without LLM calls

---

## Context Documents

- **Master Architecture**: `startupai-crew/docs/master-architecture/`
- **ADR-005 (Split API)**: `startupai-crew/docs/adr/005-state-first-synchronized-loop.md`
- **Plan File**: `/home/chris/.claude/plans/hidden-knitting-canyon.md`
- **User Stories**: `docs/user-experience/stories/README.md` (US-F01)

---

## How to Reproduce

```bash
cd /home/chris/projects/app.startupai.site/frontend

# Start dev server
pnpm dev

# Run the test (WARNING: This costs money with current config)
pnpm test:e2e tests/e2e/16-phase0-founder-complete.spec.ts --grep "should complete full 7-stage"
```

Expected: Progress reaches 85%
Actual: Progress varies between 57-92% across runs
