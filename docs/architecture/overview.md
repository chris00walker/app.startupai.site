# 🎨 Strategyzer-Powered AI Consulting Platform
<!-- markdownlint-disable MD013 -->

> Related Docs: [Product Requirements](../product/requirements.md) · [Decision Pack](../product/decision_pack.md) · [Policy DSL](../policy/dsl.md) · [Evaluation Rubrics](../evaluation/rubrics.md) · [Experiment Catalog](../experiments/catalog.md) · [Data Architecture](./data.md) · [Engineering Guide](../engineering/implementation.md) · [Operations](../operations/operations.md) · [Integrations](../integrations/overview.md) · [Diagrams Viewer](./diagrams/viewer.html)

## Vision: Visual Canvas Generation at Scale

Transform complex strategic analysis into the proven visual frameworks that clients love - **Business Model Canvas**, **Value Proposition Canvas**, and **Testing Business Ideas** methodology - all generated by sophisticated AI agents.

> *"A picture is worth a thousand words in the consulting business"* - This is why Osterwalder's visual frameworks dominate strategic consulting.

---

## Executive Summary: Solopreneur Consulting-as-Code

You are the service. This platform turns your Strategyzer playbook into an always-on, policy-routed, evaluator-guarded AI system so you can serve many clients in parallel without hiring. The system preserves your quality bar through automated stage-gates while learning from every engagement.

- Maintain your personal brand and standards with evaluator rubrics and golden scenarios
- Run 10–50 client engagements concurrently via async orchestration and event logs
- Route tasks across providers (Vertex AI, OpenAI, local tools) for the best quality/cost/latency
- Keep sensitive data in GCP; send minimal context externally; enforce guardrails
- Continuously improve with feedback loops, outcome attribution, and router policy updates

## Who We Serve (ICP)

This section has moved to a dedicated document focused on product requirements and client outcomes:

- See [product/requirements.md](../product/requirements.md) for the full Ideal Client Profile, primary challenges, and why custom solutions.
- It also contains the Client Outcome (Promise) and Deliverables Contract with acceptance criteria.

## Client Outcome (Promise) & Deliverables

Moved to [product/requirements.md](../product/requirements.md).

## Operating Model & Service Tiers

- Standard: fully automated workflows with published canvases and artefacts
- Premium: human-in-the-loop checkpoints at high-value stages (e.g., final critique/sign-off)
- Client pods: per-client workspace, vector namespace, and dashboards for transparency
- Weekly product ops: use monitoring insights to refine prompts, thresholds, and router policies

## Problem Definition & Success Criteria

**Problem.** A solopreneur consultant faces a capacity ceiling, quality drift across clients, context switching, rising inference costs, and strict data-protection needs. They need to deliver Strategyzer-standard outcomes at scale without hiring.

**Constraints:**

- GCP-native data plane only (Cloud SQL Postgres + pgvector). No MongoDB or self-hosted DBs.
- PII and sensitive data remain in GCP; send minimal context externally.
- Cloud Run limits (CPU/RAM/timeout/concurrency) apply to orchestrators and renderer.
- Solopreneur budget/time; prefer policy, automation, and learning over manual ops.

**Non-Goals:**

- Training/custom-hosting foundation models.
- Tight coupling to any single AI provider.
- Building bespoke infra outside GCP managed services.

**Personas.** Solopreneur Consultant (primary), Client Stakeholder (consumer), Reviewer/Approver (quality gate), Platform Operator (same person as consultant in most cases).

**Success Criteria.**

- Quality: evaluator composite score ≥ target per canvas (e.g., VPC ≥ 0.85; BMC ≥ 0.80).
- Latency: p95 end-to-end discovery ≤ 180s; single agent p95 ≤ 8s; renderer p95 ≤ 8s.
- Cost: per-canvas cap standard ≤ $0.75, premium ≤ $2.00; per-client monthly cap; per-request max.
- Safety: zero PII exfiltration outside policy; guardrails enforced with audit trail.

### Behavior-driven goals (preview)

- Generate Strategyzer-compliant canvases from structured inputs with defined quality/latency SLOs.
- Orchestrate multi-agent debate/consensus with evaluator-guarded stage gates.
- Provide real-time progress, recover from failures, and preserve partial results.
- Support human-AI collaborative iteration and branded, professional exports.
- Respect per-client budgets and cost guardrails with degradations and fallbacks.

[See full BDD scenarios](#behavior-driven-development-bdd-scenarios)

## eCommerce Validation Workflow (Online‑Only)

1. Intake (5 questions) → select eCom policy preset via Policy Router.
2. Plan: choose experiments (smoke page, fake door, price probe, paid pulse, matrix, checkout emu).
3. Execute: run online experiments only; collect metrics.
4. Evaluate: rubric benchmarks by vertical (CTR, CPC, CVR to intent, price elasticity delta, evidence score).
5. Decide: Green/Yellow/Red + next 3 actions.
6. Deliver: one‑page plan + evidence pack; versioned artifacts with lineage.

See diagrams: [diagrams/viewer.html](./diagrams/viewer.html) renders the sequence and learning loop.

### Experiment Catalog (Online TBI Adaptation)

- Moved to [experiments/catalog.md](../experiments/catalog.md).

### Policy Router: eCom Presets (DSL)

Details and YAML presets moved to [policy/dsl.md](../policy/dsl.md).

### Evaluator Rubrics & Benchmarks (eCom)

Moved to [evaluation/rubrics.md](../evaluation/rubrics.md).

## 🎯 Core Strategyzer Frameworks to Implement

### 1. **Value Proposition Design**

- **Customer Profile**: Jobs-to-be-done, Pains, Gains
- **Value Map**: Products & Services, Pain Relievers, Gain Creators
- **Fit Assessment**: Product-Market Fit validation

### 2. **Business Model Generation**

- **9 Building Blocks**: Key Partners, Activities, Resources, Value Props, Customer Relationships, Channels, Segments, Cost Structure, Revenue Streams
- **Visual Canvas**: Interactive, client-ready presentation format

### 3. **Testing Business Ideas**

- **Experiment Library**: 43+ experiment types organized by cost/time/evidence
- **Evidence-Based Validation**: Bulletproof case building for scaling
- **Risk Reduction**: Systematic hypothesis testing

---

## 🧠 Strategyzer AI 2.0 — ML/AI‑First Architecture

This replaces the previous agent listing with an adaptive, measurable, and continuously learning architecture. The goal is to optimize quality, cost, and latency while preserving Strategyzer methodology and keeping data/control in GCP.

### Pillars

- Adaptive multi‑agent orchestration with a Policy Router (runtime Mixture‑of‑Experts).
- Hybrid providers behind adapters (OpenAI, Vertex AI, local tools) to avoid lock‑in.
- Continuous learning loop from user edits, feedback, golden tasks, and outcomes.
- GCP‑native data plane (Cloud SQL Postgres + pgvector) with auditability and security.

### Policy Router (Agent‑level MoE)

- Selects expert path per request based on task type, domain, sensitivity/PII, latency/cost SLOs, historical evaluations, and current budget.
- v1: rule‑based with thresholds and provider preferences.
- v2: contextual bandits where reward = quality − cost − latency penalties; features/logs in Vertex AI Feature Store; versions tracked in Vertex Experiments/Registry.

#### Policy DSL (example)

```yaml
version: 1
routes:
  - match:
      task: "render"
      pii: "low"
      budget_tier: "standard"
    choose:
      provider_order: ["LocalAdapter", "OpenAIAdapter"]
      model: "gpt-4o-mini"
      max_cost_usd: 0.05
      latency_p95_ms: 8000
  - match:
      task: "analysis"
      pii: "high"
    choose:
      provider_order: ["VertexAIAdapter"]
      model: "gemini-1.5-pro-safe"
      context_policy: "minimal"
      max_cost_usd: 0.15
      latency_p95_ms: 6000
defaults:
  fallback_provider: "VertexAIAdapter"
  on_violation: "pause_and_require_approval"
```

#### Router telemetry (decision log)

- `decision_id`, `policy_version`, `request_id`
- `features`: task, pii, budget_tier, context_size, historical_quality
- `choice`: provider, model, template, retries
- `targets`: quality_goal, latency_p95_ms, max_cost_usd
- `estimates`: cost_usd, tokens, duration_ms
- `outcome`: quality, latency_ms, cost_usd, success

Note: maintain a decision table per task type (VPC, BMC, TBI, Render) for readability and audits.

### Economics & Cost Guardrails

- Per-task and per-canvas budget caps with hard stops and graceful degradation paths
- Tiered model selection: economical models for boilerplate; premium models for high-ambiguity reasoning
- Caching and reuse: deduplicate research, reuse blocks across canvases, vector-cache frequent queries
- Budget-aware routing: router considers remaining monthly/client budgets and chooses accordingly

### Provider Adapters

- `OpenAIAdapter`, `VertexAIAdapter`, `LocalAdapter` implement a common interface: `generate()`, `tools`, `cost()`, `telemetry()`.
- Enables choosing best‑of‑breed per subtask (planning, research, synthesis, tool‑use, rendering) without changing business logic or prompts.

### Orchestration Patterns that Scale You

- Hub-and-Spoke: orchestrator fans out to specialists (VPC, BMC, Research, Canvas Renderer, Evaluators)
- Stage Gates: draft → critique → improve → finalize; auto-advance only if thresholds pass
- Human-in-the-Loop on Exceptions: you review when quality/safety thresholds fail or for premium clients
- Batch + Async: Pub/Sub and Cloud Tasks queue heavy jobs; Workflows manage long-running chains
- Replayable Events: immutable event log enables audits, reprocessing with new models, and rollbacks

### Evaluators & Guardrails

- Critic/verifier agents score outputs for factuality, completeness, methodology adherence, safety, and PII.
- Vertex Guardrails for policy enforcement plus repair loops before persist/publish.
- Golden tasks per canvas type protect against regressions in CI/CD.

### Architecture Diagrams

- Orchestration Sequence: see `docs/diagrams/orchestration_sequence.mmd`.
- Learning Loop: see `docs/diagrams/learning_loop.mmd`.

### RAG & Knowledge Graph (Postgres/pgvector)

- Artefacts, transcripts, client docs embedded with pgvector; ANN indexes (ivfflat/HNSW) tuned per table.
- SQL for vector search: `ORDER BY embedding <-> $1 LIMIT k` with metadata filters via JSONB.
- Strategy Knowledge Graph tables: hypotheses → evidence → decisions → outcomes for traceability and attribution.

### Orchestration on GCP

- Cloud Run services: `gateway` (API), `orchestrator` (policy + agents), `renderer` (canvas), `monitoring`, `security-testing`.
- Pub/Sub for fan‑out, Cloud Tasks for retries/backoff/idempotency, Workflows for long chains; structured `events` table for audit.
- Secret Manager, per‑service IAM, optional Serverless VPC Access.

### Renderer Stability Playbook (Cloud Run + Puppeteer/Chromium)

- Base image: use a maintained Chromium-enabled image or install deps in Docker; ensure fonts and locales are present.
- Launch flags: `--no-sandbox`, `--disable-dev-shm-usage`, `--disable-setuid-sandbox`, `--disable-gpu`, `--single-process` (only if needed).
- Filesystem: write to `/tmp` only; ensure `XDG_CACHE_HOME=/tmp/.cache` to avoid write errors.
- Resources: start with Cloud Run 2 vCPU / 2–4 GiB RAM; adjust concurrency=1 for renderers; enable CPU always allocated for faster cold start page loads.
- Timeouts & retries: set request timeout ≥ 120s for large canvases; use Cloud Tasks with retry/backoff for idempotent render jobs.
- Fonts: install common fonts (Noto, DejaVu) to improve text consistency across locales.
- Example launcher:

```javascript
import puppeteer from 'puppeteer';

export async function launchBrowser() {
  return await puppeteer.launch({
    args: [
      '--no-sandbox',
      '--disable-setuid-sandbox',
      '--disable-dev-shm-usage',
      '--disable-gpu',
    ],
    headless: 'new',
  });
}
```

### MLOps on Vertex AI

- Pipelines: nightly curation → evaluator/router training → register → staged rollout and rollback.
- Feature Store for routing features & rewards; Experiments for comparison; Model Registry for versioning.
- Batch embedding refresh and drift checks; budget enforcement baked into pipelines.

### Security & Compliance

- PII encryption at rest (app‑layer for designated fields) per org standards; keys via Secret Manager.
- Minimal context to external providers; sensitive data stays in GCP.
- Maintain CI/CD security gates (dependency, secret, IaC, container scans) and Audit Logging.

### Observability, SLOs & Ops

- Telemetry: OpenTelemetry SDK exports traces/metrics/logs → Cloud Trace/Monitoring/Logging; per-request correlation IDs.
- Core SLOs (targets):
  - Quality: evaluator composite ≥ 0.85 (VPC), ≥ 0.80 (BMC), ≥ 0.80 (TBI).
  - Latency: p95 end-to-end discovery ≤ 180s; single agent p95 ≤ 8s; renderer p95 ≤ 8s.
  - Cost: per-canvas cap standard ≤ $0.75, premium ≤ $2.00; per-client monthly cap; per-request max.
  - Reliability: error budget ≤ 2% failed publishes / 30 days.
  - Observability: 100% of router decisions logged with correlation IDs.
- Dashboards: Cloud Monitoring for quality/latency/cost; alerts on burn rate, error spikes, budget exhaustion.
- Auditability: immutable `events` + `router_decisions` tables; replay tooling gated by budget + safety policy.

Operational responses when SLOs breach:

- Quality: pause auto-publish, route to human review, open an incident, create golden tasks for regressions.
- Latency: scale Cloud Run, reduce context size, degrade to cheaper/faster model tier per policy.
- Cost: trigger cost breaker, require approval, switch to degraded prompts or local tools, reschedule heavy jobs.

### TDD/BDD on GCP

- Contract tests at adapter boundary; golden scenarios for VPC/BMC/TBI with evaluator thresholds.
- Integration with Postgres/pgvector; e2e smokes against Cloud Run; cost/latency assertions with SLO bounds.

#### Expanded TDD/BDD for ML/AI‑first Workflows

- Unit: prompt builders, parsers, evaluators; deterministic with fixtures.
- Contract: `OpenAIAdapter`/`VertexAIAdapter` wire-format, error semantics, cost reporting.
- Golden tests: curated client scenarios with locked inputs and expected evaluator scores.
- E2E: orchestrator happy-path and failure-path through stage gates; renderer smoke tests (SVG diff tolerance).
- Non-functional: load/cost tests verify router respects budget caps; chaos tests for provider timeouts.

### Minimal Data Model Additions (Postgres)

- `events(id, workflow_id, agent, type, payload_jsonb, created_at)` immutable event log.
- `feedback(id, artefact_id, signal, edit_distance, time_to_accept, user_id, created_at)`.
- `evaluations(id, artefact_id, quality, safety, completeness, latency_ms, cost_usd, created_at)`.
- `router_decisions(id, request_id, features_jsonb, choice, reward, created_at)`.

### **Business Model Generation Agents**

#### **Customer Segments Agent**

```javascript
Purpose: Define and analyze customer segments
Methodology: Osterwalder Customer Segmentation
Inputs: Market research, customer data, behavioral analysis
Outputs:
- Mass market vs. niche segments
- Multi-sided platforms
- Diversified segments
- Segmented markets

Visual Artifacts Generated:
- Customer Segments Canvas section
- Segment Prioritization Matrix
- Customer Persona Cards
```

#### **Value Propositions Agent**

```javascript
Purpose: Articulate unique value propositions
Methodology: Strategyzer Value Proposition methodology
Inputs: Customer insights, competitive analysis, capabilities
Outputs:
- Newness and innovation value
- Performance improvements
- Customization value
- Getting the job done value
- Design and brand value
- Price and cost reduction value

Visual Artifacts Generated:
- Value Propositions Canvas section
- Value Hierarchy Diagram
- Competitive Value Map
```

#### **Channels Agent**

```javascript
Purpose: Design customer touchpoint strategy
Methodology: Osterwalder Channels framework
Inputs: Customer journey, market analysis, distribution options
Outputs:
- Awareness channels
- Evaluation channels
- Purchase channels
- Delivery channels
- After-sales channels

Visual Artifacts Generated:
- Channels Canvas section
- Customer Journey Channel Map
- Channel Strategy Matrix
```

#### **Customer Relationships Agent**

```javascript
Purpose: Define customer relationship strategy
Methodology: Strategyzer Customer Relationships framework
Inputs: Customer lifecycle, service strategy, automation capabilities
Outputs:
- Personal assistance relationships
- Dedicated personal assistance
- Self-service relationships
- Automated services
- Communities and co-creation

Visual Artifacts Generated:
- Customer Relationships Canvas section
- Relationship Strategy Map
- Customer Lifecycle Journey
```

#### **Revenue Streams Agent**

```javascript
Purpose: Design monetization strategy
Methodology: Osterwalder Revenue Streams framework
Inputs: Value propositions, customer willingness to pay, market analysis
Outputs:
- Asset sale revenue
- Usage fee revenue
- Subscription revenue
- Lending/renting/leasing revenue
- Licensing revenue
- Brokerage fees
- Advertising revenue

Visual Artifacts Generated:
- Revenue Streams Canvas section
- Revenue Model Comparison
- Pricing Strategy Matrix
```

#### **Key Resources Agent**

```javascript
Purpose: Identify critical business resources
Methodology: Strategyzer Key Resources framework
Inputs: Value propositions, operations analysis, competitive advantages
Outputs:
- Physical resources
- Intellectual resources
- Human resources
- Financial resources

Visual Artifacts Generated:
- Key Resources Canvas section
- Resource Dependency Map
- Resource Optimization Plan
```

#### **Key Activities Agent**

```javascript
Purpose: Define core business activities
Methodology: Osterwalder Key Activities framework
Inputs: Value propositions, business processes, operational requirements
Outputs:
- Production activities
- Problem-solving activities
- Platform/network activities

Visual Artifacts Generated:
- Key Activities Canvas section
- Activity Value Chain
- Process Optimization Map
```

#### **Key Partnerships Agent**

```javascript
Purpose: Design strategic partnership strategy
Methodology: Strategyzer Key Partnerships framework
Inputs: Resource requirements, risk analysis, market opportunities
Outputs:
- Strategic alliances
- Joint ventures
- Buyer-supplier relationships
- Coopetition partnerships

Visual Artifacts Generated:
- Key Partnerships Canvas section
- Partnership Strategy Map
- Alliance Value Network
```

#### **Cost Structure Agent**

```javascript
Purpose: Analyze and optimize cost structure
Methodology: Osterwalder Cost Structure framework
Inputs: Key activities, resources, partnerships, financial data
Outputs:
- Cost-driven vs. value-driven structure
- Fixed vs. variable costs
- Economies of scale and scope

Visual Artifacts Generated:
- Cost Structure Canvas section
- Cost Breakdown Analysis
- Cost Optimization Roadmap
```

### **Testing Business Ideas Agents**

#### **Hypothesis Formation Agent**

```javascript
Purpose: Convert assumptions into testable hypotheses
Methodology: Strategyzer Hypothesis framework
Inputs: Business model assumptions, risk analysis, uncertainty mapping
Outputs:
- Desirability hypotheses (do customers want this?)
- Feasibility hypotheses (can we build this?)
- Viability hypotheses (can we make money?)

Visual Artifacts Generated:
- Hypothesis Prioritization Matrix
- Risk-Evidence Map
- Testing Roadmap
```

#### **Experiment Design Agent**

```javascript
Purpose: Design experiments from 43+ Strategyzer experiment library
Methodology: Testing Business Ideas experiment selection
Inputs: Hypotheses, resources, timeline, evidence requirements
Outputs:
- Experiment selection and design
- Success metrics definition
- Resource requirements
- Timeline and milestones

Visual Artifacts Generated:
- Experiment Design Canvas
- Evidence Requirements Matrix
- Testing Timeline (Gantt chart)
```

#### **Evidence Collection Agent**

```javascript
Purpose: Gather and analyze experiment evidence
Methodology: Strategyzer Evidence framework
Inputs: Experiment results, customer feedback, market data
Outputs:
- Evidence strength assessment
- Hypothesis validation/invalidation
- Learning insights
- Next experiment recommendations

Visual Artifacts Generated:
- Evidence Dashboard
- Learning Insights Report
- Hypothesis Validation Matrix
```

---

## 🎨 Visual Canvas Generation System

### **Interactive Business Model Canvas Generator**

```javascript
class BusinessModelCanvasGenerator {
  async generateCanvas(businessModelData) {
    const canvas = await this.createInteractiveSVG({
      template: 'strategyzer_business_model_canvas',
      dimensions: { width: 1200, height: 800 },
      sections: {
        keyPartners: {
          position: { x: 0, y: 0, width: 200, height: 400 },
          content: businessModelData.keyPartners,
          styling: { backgroundColor: '#E8F4FD', borderColor: '#1976D2' }
        },
        keyActivities: {
          position: { x: 200, y: 0, width: 200, height: 200 },
          content: businessModelData.keyActivities,
          styling: { backgroundColor: '#F3E5F5', borderColor: '#7B1FA2' }
        },
        keyResources: {
          position: { x: 200, y: 200, width: 200, height: 200 },
          content: businessModelData.keyResources,
          styling: { backgroundColor: '#E8F5E8', borderColor: '#388E3C' }
        },
        valuePropositions: {
          position: { x: 400, y: 0, width: 200, height: 400 },
          content: businessModelData.valuePropositions,
          styling: { backgroundColor: '#FFF3E0', borderColor: '#F57C00' }
        },
        customerRelationships: {
          position: { x: 600, y: 0, width: 200, height: 200 },
          content: businessModelData.customerRelationships,
          styling: { backgroundColor: '#FCE4EC', borderColor: '#C2185B' }
        },
        channels: {
          position: { x: 600, y: 200, width: 200, height: 200 },
          content: businessModelData.channels,
          styling: { backgroundColor: '#F1F8E9', borderColor: '#689F38' }
        },
        customerSegments: {
          position: { x: 800, y: 0, width: 200, height: 400 },
          content: businessModelData.customerSegments,
          styling: { backgroundColor: '#E3F2FD', borderColor: '#1565C0' }
        },
        costStructure: {
          position: { x: 0, y: 400, width: 500, height: 200 },
          content: businessModelData.costStructure,
          styling: { backgroundColor: '#FFEBEE', borderColor: '#D32F2F' }
        },
        revenueStreams: {
          position: { x: 500, y: 400, width: 500, height: 200 },
          content: businessModelData.revenueStreams,
          styling: { backgroundColor: '#E8F5E8', borderColor: '#2E7D32' }
        }
      },
      interactivity: {
        hover: 'highlight_section',
        click: 'edit_content',
        export: ['pdf', 'png', 'svg']
      },
      branding: {
        logo: 'client_logo',
        colors: 'client_brand_colors',
        fonts: 'professional_typography'
      }
    });

    return {
      canvas,
      metadata: {
        type: 'business_model_canvas',
        framework: 'strategyzer',
        generatedBy: 'BusinessModelCanvasGenerator',
        clientReady: true,
        lastUpdated: new Date()
      }
    };
  }
}
```

### **Value Proposition Canvas Generator**

```javascript
class ValuePropositionCanvasGenerator {
  async generateCanvas(valuePropositionData) {
    const canvas = await this.createInteractiveSVG({
      template: 'strategyzer_value_proposition_canvas',
      layout: 'two_circles_interlocked',
      sections: {
        customerProfile: {
          shape: 'circle',
          position: 'left',
          subsections: {
            customerJobs: {
              position: 'top',
              content: valuePropositionData.customerJobs,
              styling: { color: '#1976D2', icon: 'work' }
            },
            pains: {
              position: 'left',
              content: valuePropositionData.pains,
              styling: { color: '#D32F2F', icon: 'warning' }
            },
            gains: {
              position: 'right',
              content: valuePropositionData.gains,
              styling: { color: '#388E3C', icon: 'trending_up' }
            }
          }
        },
        valueMap: {
          shape: 'circle',
          position: 'right',
          subsections: {
            productsServices: {
              position: 'top',
              content: valuePropositionData.productsServices,
              styling: { color: '#7B1FA2', icon: 'inventory' }
            },
            painRelievers: {
              position: 'left',
              content: valuePropositionData.painRelievers,
              styling: { color: '#F57C00', icon: 'healing' }
            },
            gainCreators: {
              position: 'right',
              content: valuePropositionData.gainCreators,
              styling: { color: '#689F38', icon: 'star' }
            }
          }
        },
        fitIndicators: {
          position: 'center_overlap',
          content: valuePropositionData.fitAssessment,
          styling: { color: '#FF5722', icon: 'target' }
        }
      }
    });

    return canvas;
  }
}
```

### **Testing Business Ideas Dashboard Generator**

```javascript
class TestingDashboardGenerator {
  async generateDashboard(testingData) {
    const dashboard = await this.createInteractiveDashboard({
      template: 'strategyzer_testing_dashboard',
      sections: {
        hypothesesMatrix: {
          type: 'risk_evidence_matrix',
          axes: { x: 'Evidence Strength', y: 'Business Risk' },
          data: testingData.hypotheses,
          quadrants: {
            topLeft: { label: 'High Risk, Low Evidence', color: '#D32F2F' },
            topRight: { label: 'High Risk, High Evidence', color: '#FF9800' },
            bottomLeft: { label: 'Low Risk, Low Evidence', color: '#FFC107' },
            bottomRight: { label: 'Low Risk, High Evidence', color: '#4CAF50' }
          }
        },
        experimentLibrary: {
          type: 'experiment_cards',
          experiments: testingData.experiments,
          filters: ['cost', 'time', 'evidence_strength'],
          sorting: ['priority', 'feasibility', 'impact']
        },
        evidenceTracker: {
          type: 'progress_tracker',
          metrics: testingData.evidenceMetrics,
          visualizations: ['progress_bars', 'trend_charts', 'success_indicators']
        }
      }
    });

    return dashboard;
  }
}
```

---

## 🔄 Strategyzer Workflow Orchestration

### **Phase 1: Value Proposition Design**

```javascript
async function executeValuePropositionPhase(clientData) {
  // Step 1: Customer Profile Development
  const customerJobs = await CustomerJobsAgent.analyze(clientData);
  const customerPains = await CustomerPainsAgent.identify(clientData);
  const customerGains = await CustomerGainsAgent.discover(clientData);
  
  // Step 2: Value Map Creation
  const valueMap = await ValueMapAgent.design({
    customerProfile: { customerJobs, customerPains, customerGains },
    capabilities: clientData.capabilities,
    competitive: clientData.competitiveAnalysis
  });
  
  // Step 3: Fit Assessment
  const fitAssessment = await FitAssessmentAgent.validate({
    customerProfile: { customerJobs, customerPains, customerGains },
    valueMap: valueMap,
    marketEvidence: clientData.marketEvidence
  });
  
  // Generate Visual Canvas
  const valuePropositionCanvas = await ValuePropositionCanvasGenerator.generate({
    customerJobs, customerPains, customerGains,
    productsServices: valueMap.productsServices,
    painRelievers: valueMap.painRelievers,
    gainCreators: valueMap.gainCreators,
    fitAssessment: fitAssessment
  });
  
  return {
    artifacts: [valuePropositionCanvas],
    insights: fitAssessment.insights,
    recommendations: fitAssessment.recommendations,
    nextPhase: 'business_model_generation'
  };
}
```

### **Phase 2: Business Model Generation**

```javascript
async function executeBusinessModelPhase(valuePropositionResults, clientData) {
  // Parallel execution of all 9 building blocks
  const [
    customerSegments,
    valuePropositions,
    channels,
    customerRelationships,
    revenueStreams,
    keyResources,
    keyActivities,
    keyPartnerships,
    costStructure
  ] = await Promise.all([
    CustomerSegmentsAgent.analyze(clientData),
    ValuePropositionsAgent.refine(valuePropositionResults),
    ChannelsAgent.design(clientData),
    CustomerRelationshipsAgent.strategy(clientData),
    RevenueStreamsAgent.model(clientData),
    KeyResourcesAgent.identify(clientData),
    KeyActivitiesAgent.map(clientData),
    KeyPartnershipsAgent.strategy(clientData),
    CostStructureAgent.analyze(clientData)
  ]);
  
  // Generate Business Model Canvas
  const businessModelCanvas = await BusinessModelCanvasGenerator.generate({
    customerSegments, valuePropositions, channels, customerRelationships,
    revenueStreams, keyResources, keyActivities, keyPartnerships, costStructure
  });
  
  return {
    artifacts: [businessModelCanvas],
    businessModel: { /* all 9 building blocks */ },
    nextPhase: 'testing_business_ideas'
  };
}
```

### **Phase 3: Testing Business Ideas**

```javascript
async function executeTestingPhase(businessModelResults, clientData) {
  // Step 1: Hypothesis Formation
  const hypotheses = await HypothesisFormationAgent.generate({
    businessModel: businessModelResults.businessModel,
    assumptions: clientData.assumptions,
    risks: clientData.risks
  });
  
  // Step 2: Experiment Design
  const experiments = await ExperimentDesignAgent.select({
    hypotheses: hypotheses,
    resources: clientData.resources,
    timeline: clientData.timeline,
    evidenceRequirements: clientData.evidenceRequirements
  });
  
  // Step 3: Evidence Collection Framework
  const evidenceFramework = await EvidenceCollectionAgent.design({
    experiments: experiments,
    metrics: clientData.successMetrics,
    tools: clientData.analyticsTools
  });
  
  // Generate Testing Dashboard
  const testingDashboard = await TestingDashboardGenerator.generate({
    hypotheses: hypotheses,
    experiments: experiments,
    evidenceMetrics: evidenceFramework.metrics
  });
  
  return {
    artifacts: [testingDashboard],
    testingPlan: { hypotheses, experiments, evidenceFramework },
    nextPhase: 'continuous_optimization'
  };
}
```

---

## 📊 Cloud SQL (Postgres) Schema for Strategyzer Artifacts

### **Canvas Artifact Model (Prisma + Postgres/pgvector)**

```sql
-- Postgres schema (conceptual)
CREATE TABLE canvas_artifacts (
  id              UUID PRIMARY KEY,
  client_id       UUID NOT NULL,
  framework_type  TEXT NOT NULL CHECK (framework_type IN (
    'value_proposition_canvas', 'business_model_canvas', 'testing_dashboard'
  )),
  canvas_version  TEXT NOT NULL DEFAULT '1.0',

  -- Visual canvas data
  visual_content        TEXT,            -- SVG markup
  interactive_elements  JSONB,           -- interactive config/state

  -- Structured sections
  sections              JSONB NOT NULL DEFAULT '{}',

  -- Presentation metadata
  presentation          JSONB NOT NULL DEFAULT '{}',

  -- Collaboration and iteration
  collaboration         JSONB NOT NULL DEFAULT '{}',

  -- AI generation metadata
  generation            JSONB NOT NULL DEFAULT '{}',

  -- Vector for semantic search (optional, for summaries)
  embedding             VECTOR(1536),

  created_at       TIMESTAMPTZ NOT NULL DEFAULT now(),
  updated_at       TIMESTAMPTZ NOT NULL DEFAULT now()
);

-- Example pgvector index
CREATE INDEX IF NOT EXISTS idx_canvas_artifacts_embedding
  ON canvas_artifacts USING ivfflat (embedding vector_cosine_ops);
```

```prisma
// Prisma model (representative)
model CanvasArtifact {
  id                 String   @id @default(uuid())
  clientId           String   @db.Uuid
  frameworkType      String
  canvasVersion      String   @default("1.0")

  visualContent      String?
  interactiveElements Json?
  sections           Json     @default("{}")
  presentation       Json     @default("{}")
  collaboration      Json     @default("{}")
  generation         Json     @default("{}")

  // Store embedding in a companion table or as bytea/array if preferred; raw SQL used for ANN queries
  createdAt          DateTime @default(now())
  updatedAt          DateTime @updatedAt
}
```

---

## 🎯 Implementation Roadmap

### **Phase 1: Value Proposition Canvas (Weeks 1-2)**

- [ ] Implement Customer Jobs, Pains, Gains agents
- [ ] Build Value Map agent
- [ ] Create Fit Assessment agent
- [ ] Develop interactive Value Proposition Canvas generator
- [ ] Test with real client data

### **Phase 2: Business Model Canvas (Weeks 3-4)**

- [ ] Implement all 9 building block agents
- [ ] Create Business Model Canvas generator
- [ ] Build canvas collaboration features
- [ ] Add export capabilities (PDF, PNG, SVG)

### **Phase 3: Testing Business Ideas (Weeks 5-6)**

- [ ] Implement Hypothesis Formation agent
- [ ] Build Experiment Design agent with 43+ experiment library
- [ ] Create Evidence Collection agent
- [ ] Develop Testing Dashboard generator

### Planned Evolution (Q4 2025)

1. **Separate Version Table** – Introduce `canvas_versions` storing diffs; main `canvas_artifacts` gains `active_version_id` pointer.
2. **Hierarchical JSON Schema** – Keep `sections` as structured JSONB with fine-grained updates by path.
3. **Vector Search Enablement** – Use `pgvector` on semantic fields for retrieval augmented generation; maintain ANN indexes (ivfflat/HNSW) with appropriate tuning.
4. **Real-time Collaboration** – Use Pub/Sub or Eventarc to trigger updates and push via WebSocket gateway; avoid DB-specific change streams.
5. **On-Demand Export Service** – Decouple media generation; a serverless `export-service` renders PDF/SVG on request and caches assets in Cloud Storage.
6. **Backward Compatibility Layer** – Dual-write during migration; legacy API/tests still operate on prior shape until Phase 3.

### Incremental Roll-out

| Phase | Goal | Key Tasks |
|-------|------|-----------|
| 0 | Stabilise current model & tests | Finish CI fixes (current sprint) |
| 1 | Dual-write | Write canvases in both schemas behind `CANVAS_V2` flag |
| 2 | Read-path switch | Update agents & routes to consume v2 schema; maintain export compatibility via service |
| 3 | Legacy removal | Delete `versions[]`, binary storage, and old tests once coverage parity achieved |

> **Action item:** All new features touching canvases must respect `CANVAS_V2` feature flag and write to both schemas.

---

## 🧠 Advanced AI-Optimized Architecture

### **Cloud SQL Schema for AI Workflows (Prisma + Postgres/pgvector)**

```prisma
model Artefact {
  id            String   @id @default(uuid())
  clientId      String   @db.Uuid
  agentId       String?
  agentType     String?
  workflowId    String?
  workflowStage String?

  contentRaw        Json?
  contentStructured Json?
  contentMetadata   Json?

  execution         Json?   // input_context, output_context, agent_state, deps
  validation        Json?   // validated flags, scores, notes

  searchableContent String?
  tags              Json?
  keywords          Json?

  createdAt      DateTime @default(now())
  updatedAt      DateTime @updatedAt
}
```

### **Advanced Query Capabilities**

#### 1. **Contextual Artefact Retrieval**

```typescript
// Prisma example (relevance approximated via sort priority and stage match)
const getContextualArtefacts = async (clientId: string, currentStage: string) => {
  return prisma.artefact.findMany({
    where: { clientId },
    orderBy: [
      { workflowStage: 'desc' }, // ensure exact stage sorted via CASE in raw SQL if needed
      { createdAt: 'desc' }
    ],
    take: 5
  });
};
```

#### 2. **AI-Powered Insights Generation**

```sql
-- Aggregate insights from JSONB
SELECT
  insight,
  COUNT(*)                     AS frequency,
  AVG((content->'structured'->>'confidence')::numeric) AS avg_confidence
FROM (
  SELECT jsonb_array_elements(content->'structured'->'insights') AS insight, content
  FROM artefacts
  WHERE client_id = $1 AND (content->'metadata'->>'status') = 'completed'
) t
GROUP BY insight
ORDER BY frequency DESC, avg_confidence DESC;
```

#### 3. **Quality Assessment Pipeline**

```sql
-- Per-stage quality summary
SELECT
  workflow_stage,
  AVG((content->'metadata'->>'quality_score')::numeric) AS avg_quality,
  COUNT(*)                                              AS total_artefacts,
  AVG((content->'metadata'->>'processing_time')::numeric) AS avg_processing_time,
  SUM((content->'metadata'->>'cost')::numeric)            AS total_cost
FROM artefacts
WHERE client_id = $1
GROUP BY workflow_stage
ORDER BY avg_quality DESC;
```

---

## 🤝 Collaborative Multi-Agent Architecture

### **Shared Canvas Collaboration Model**

```javascript
// Collaborative Canvas Data Structure
const CollaborativeCanvas = {
  id: "canvas_uuid",
  type: "value_proposition_canvas",
  version: 3,
  lastUpdated: "2025-01-15T10:30:00Z",
  
  // Shared workspace with agent collaboration
  workspace: {
    customerProfile: {
      jobs: {
        functional: [],
        emotional: [],
        social: [],
        lastUpdatedBy: "customer_discovery_agent",
        lastUpdated: "2025-01-15T10:25:00Z",
        comments: [
          {
            agent: "market_research_agent",
            comment: "Consider enterprise vs SMB job differences",
            timestamp: "2025-01-15T10:26:00Z",
            confidence: 0.85
          }
        ],
        debates: [
          {
            initiator: "customer_discovery_agent",
            challenger: "market_research_agent",
            topic: "Job priority ranking",
            resolution: "consensus",
            outcome: "Updated job prioritization based on market data"
          }
        ]
      },
      pains: {
        data: [],
        lastUpdatedBy: "customer_discovery_agent",
        confidence: 0.85,
        validatedBy: ["simulation_agent"],
        challengedBy: ["critique_agent"],
        status: "validated"
      }
    },
    
    valueMap: {
      productsServices: {
        data: [],
        lastUpdatedBy: "value_proposition_agent",
        simulationResults: {
          marketFit: 0.78,
          feasibility: 0.82,
          lastSimulated: "2025-01-15T10:28:00Z"
        },
        validationExperiments: [
          {
            hypothesis: "Feature X reduces pain Y by 50%",
            designedBy: "validation_agent",
            status: "pending",
            expectedOutcome: "Validated pain relief"
          }
        ]
      }
    }
  },
  
  // Agent collaboration metadata
  collaboration: {
    activeAgents: ["customer_discovery_agent", "value_proposition_agent"],
    debateHistory: [],
    consensusItems: [],
    pendingResolutions: []
  }
};
```

### **Agent Debate and Consensus System**

```javascript
class AgentDebateManager {
  constructor() {
    this.activeDebates = new Map();
    this.consensusThreshold = 0.8;
  }
  
  async initiateDebate(canvasId, section, initiatorAgent, challengerAgent, topic) {
    const debate = {
      id: generateDebateId(),
      canvasId,
      section,
      initiator: initiatorAgent,
      challenger: challengerAgent,
      topic,
      arguments: [],
      status: 'active',
      startTime: new Date()
    };
    
    this.activeDebates.set(debate.id, debate);
    return debate.id;
  }
  
  async addArgument(debateId, agent, argument, evidence) {
    const debate = this.activeDebates.get(debateId);
    debate.arguments.push({
      agent,
      argument,
      evidence,
      timestamp: new Date(),
      confidence: evidence.confidence || 0.5
    });
    
    // Check for consensus
    if (this.checkConsensus(debate)) {
      await this.resolveDebate(debateId);
    }
  }
  
  checkConsensus(debate) {
    const recentArgs = debate.arguments.slice(-4); // Last 4 arguments
    const avgConfidence = recentArgs.reduce((sum, arg) => sum + arg.confidence, 0) / recentArgs.length;
    return avgConfidence >= this.consensusThreshold;
  }
  
  async resolveDebate(debateId) {
    const debate = this.activeDebates.get(debateId);
    debate.status = 'resolved';
    debate.endTime = new Date();
    
    // Update canvas with consensus
    await this.updateCanvasWithConsensus(debate);
    
    this.activeDebates.delete(debateId);
  }
}
```

---

## 🏢 Real-World Consulting Integration

### **Enterprise-Grade Agent Orchestration**

```javascript
// Professional Consulting Workflow Manager
class ConsultingWorkflowOrchestrator {
  constructor() {
    this.phaseManagers = {
      discovery: new CustomerDiscoveryManager(),
      validation: new CustomerValidationManager(),
      scaling: new CustomerScalingManager(),
      optimization: new CompanyOptimizationManager()
    };
  }
  
  async executeConsultingEngagement(clientId, engagementType) {
    const engagement = {
      clientId,
      type: engagementType,
      phases: ['discovery', 'validation', 'scaling'],
      currentPhase: 'discovery',
      deliverables: [],
      timeline: this.generateTimeline(engagementType),
      qualityGates: this.defineQualityGates()
    };
    
    for (const phase of engagement.phases) {
      await this.executePhase(engagement, phase);
      await this.validatePhaseCompletion(engagement, phase);
    }
    
    return engagement;
  }
  
  async executePhase(engagement, phase) {
    const manager = this.phaseManagers[phase];
    const phaseResults = await manager.execute(engagement.clientId);
    
    engagement.deliverables.push({
      phase,
      results: phaseResults,
      completedAt: new Date(),
      qualityScore: phaseResults.qualityMetrics.overall
    });
  }
}
```

### **Professional Deliverables Generation**

```javascript
// Enterprise Deliverable Templates
const CONSULTING_DELIVERABLES = {
  discovery: {
    'Market Size Analysis': {
      template: 'tam_sam_som_analysis',
      agents: ['market_research_agent', 'data_analysis_agent'],
      format: ['executive_summary', 'detailed_analysis', 'visual_charts']
    },
    'Competitive Landscape': {
      template: 'competitive_matrix',
      agents: ['competitive_intelligence_agent', 'market_research_agent'],
      format: ['competitor_profiles', 'positioning_map', 'swot_analysis']
    },
    'Customer Persona Development': {
      template: 'buyer_personas',
      agents: ['persona_development_agent', 'customer_interview_agent'],
      format: ['persona_cards', 'journey_maps', 'needs_analysis']
    }
  },
  validation: {
    'Validation Plan': {
      template: 'experiment_design',
      agents: ['validation_plan_agent', 'experiment_design_agent'],
      format: ['hypothesis_framework', 'experiment_library', 'success_metrics']
    },
    'MVP Specification': {
      template: 'mvp_definition',
      agents: ['product_definition_agent', 'technical_specification_agent'],
      format: ['feature_prioritization', 'technical_requirements', 'user_stories']
    }
  },
  scaling: {
    'Go-to-Market Strategy': {
      template: 'gtm_strategy',
      agents: ['gtm_strategy_agent', 'channel_strategy_agent'],
      format: ['channel_plan', 'pricing_strategy', 'launch_timeline']
    },
    'Financial Projections': {
      template: 'financial_model',
      agents: ['financial_modeling_agent', 'scenario_planning_agent'],
      format: ['revenue_projections', 'cost_structure', 'scenario_analysis']
    }
  }
};
```

---

## 🔮 Advanced GCP-Native AI Capabilities

### **Vector Search Integration (pgvector)**

```sql
-- Semantic Search for Strategic Insights (pgvector)
-- $1 = query embedding (vector), $2 = client_id
SELECT id,
       client_id,
       1 - (embedding <=> $1) AS score
FROM artefacts
WHERE client_id = $2
ORDER BY embedding <=> $1
LIMIT 10;
```

### **Real-time Analytics Pipeline (SQL)**

```sql
-- Live Workflow Monitoring (last 24 hours)
WITH recent AS (
  SELECT *
  FROM artefacts
  WHERE created_at >= now() - interval '24 hours'
)
SELECT
  workflow_stage,
  agent_type,
  date_trunc('hour', created_at) AS hour,
  COUNT(*) AS count,
  AVG((content->'metadata'->>'quality_score')::numeric) AS avg_quality,
  AVG((content->'metadata'->>'processing_time')::numeric) AS avg_processing_time,
  SUM((content->'metadata'->>'cost')::numeric) AS total_cost
FROM recent
GROUP BY workflow_stage, agent_type, hour
ORDER BY hour ASC;
```

### **Phase 4: Integration & Polish (Weeks 7-8)**

- [ ] End-to-end Strategyzer workflow
- [ ] Client branding and customization
- [ ] Stakeholder collaboration features
- [ ] Performance optimization

---

## 🎨 Expected Visual Deliverables

### **Client-Ready Artifacts**

1. **Interactive Value Proposition Canvas** - Professional, branded, exportable
2. **Business Model Canvas** - Complete 9-building-block visual
3. **Testing Business Ideas Dashboard** - Experiment tracking and evidence
4. **Customer Journey Maps** - Visual customer experience mapping
5. **Competitive Analysis Charts** - Market positioning visuals
6. **Financial Model Dashboards** - Revenue and cost projections

### **Quality Standards**

- **Strategyzer Methodology Compliance**: 100% adherence to proven frameworks
- **Visual Quality**: Client-presentation ready
- **Interactivity**: Hover, click, edit, export capabilities
- **Branding**: Client logo, colors, fonts applied
- **Export Options**: PDF, PNG, SVG, PowerPoint formats

---

<!-- markdownlint-disable-next-line MD033 -->
<a id="behavior-driven-development-bdd-scenarios"></a>

## 🎭 Behavior-Driven Development (BDD) Scenarios

### **Core User Behaviors & Acceptance Criteria**

BDD scenarios define *what* the system should do from the user's perspective, driving the architectural design and feature requirements.

#### **Scenario 1: Value Proposition Canvas Generation**

```gherkin
Feature: AI-Powered Value Proposition Canvas Generation
  As a strategic consultant
  I want to generate a professional Value Proposition Canvas from client input
  So that I can deliver Strategyzer-compliant strategic analysis

Scenario: Successful canvas generation for new client
  Given I have a new client with basic business information
  And the client description includes target market and challenges
  When I trigger the discovery workflow
  Then the system should execute customer jobs, pains, and gains agents
  And generate a complete Value Proposition Canvas
  And provide export options in PDF, SVG, and PNG formats
  And achieve a quality score above 85%
  And complete the process in under 3 minutes

Scenario: Canvas generation with insufficient client data
  Given I have a client with minimal business information
  When I trigger the discovery workflow
  Then the system should identify missing information
  And prompt for additional client details
  And provide guidance on required information
  And allow partial canvas generation with confidence indicators
```

#### **Scenario 2: Multi-Agent Workflow Orchestration**

```gherkin
Feature: Intelligent Multi-Agent Collaboration
  As a platform user
  I want AI agents to collaborate and validate each other's work
  So that I receive high-quality, consensus-driven strategic insights

Scenario: Agents reach consensus on customer analysis
  Given multiple agents are analyzing the same client
  When the Customer Jobs Agent identifies functional jobs
  And the Market Research Agent provides supporting data
  Then the agents should cross-validate findings
  And reach consensus on job prioritization
  And document the reasoning for their conclusions
  And achieve confidence scores above 80%

Scenario: Agents debate conflicting insights
  Given agents have conflicting analysis results
  When the Value Map Agent proposes solutions
  And the Validation Agent challenges feasibility
  Then the system should facilitate structured debate
  And require evidence-based arguments
  And reach resolution through weighted consensus
  And maintain audit trail of the debate process
```

#### **Scenario 3: Real-Time Progress Tracking**

```gherkin
Feature: Transparent Workflow Monitoring
  As a consultant managing client expectations
  I want to see real-time progress of AI workflow execution
  So that I can provide accurate updates to clients

Scenario: Workflow progress visualization
  Given a discovery workflow is executing
  When I view the workflow dashboard
  Then I should see current agent execution status
  And estimated completion time
  And quality metrics for completed agents
  And cost tracking for the workflow
  And ability to pause or modify the workflow

Scenario: Workflow failure recovery
  Given an agent fails during execution
  When the system detects the failure
  Then it should attempt automatic recovery
  And notify me of the issue
  And provide options for manual intervention
  And maintain partial results for review
```

#### **Scenario 4: Canvas Collaboration & Iteration**

```gherkin
Feature: Collaborative Canvas Refinement
  As a strategic consultant
  I want to collaborate with AI agents to refine canvas content
  So that I can deliver precisely tailored strategic recommendations

Scenario: Human-AI collaborative editing
  Given I have a generated Value Proposition Canvas
  When I provide feedback on specific sections
  Then the relevant agents should incorporate my feedback
  And regenerate affected canvas sections
  And maintain version history of changes
  And explain the reasoning for modifications

Scenario: Canvas quality validation
  Given a completed canvas
  When I request quality assessment
  Then the system should evaluate Strategyzer compliance
  And check internal consistency across sections
  And provide improvement recommendations
  And assign overall quality score
```

#### **Scenario 5: Client Deliverable Export**

```gherkin
Feature: Professional Client Deliverables
  As a consultant preparing client presentations
  I want to export canvases in multiple professional formats
  So that I can deliver polished strategic artifacts

Scenario: Multi-format canvas export
  Given I have a completed Value Proposition Canvas
  When I request export in presentation format
  Then the system should generate high-resolution PDF
  And create editable SVG version
  And provide PowerPoint-compatible PNG
  And apply client branding if configured
  And include metadata and generation timestamp

Scenario: Branded deliverable customization
  Given I have client branding requirements
  When I configure brand colors and logos
  Then all exported canvases should reflect client branding
  And maintain Strategyzer visual standards
  And ensure readability and professional appearance
  And provide brand compliance validation
```

### **BDD-Driven Architecture Decisions**

These scenarios directly influence architectural choices:

1. **Real-Time Updates**: WebSocket integration for live progress tracking
2. **Agent Collaboration**: Debate and consensus mechanisms in agent architecture
3. **Quality Assurance**: Built-in validation and scoring systems
4. **Export Flexibility**: Multi-format rendering engine with branding support
5. **Failure Recovery**: Robust error handling and partial result preservation
6. **Human-AI Collaboration**: Interactive editing and feedback integration

---

This architecture transforms the platform into a **Strategyzer-powered visual consulting engine** that generates the rich, client-ready canvases that make strategic insights immediately actionable and shareable.
